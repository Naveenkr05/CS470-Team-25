{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHvNwOvGbUG7vOgAgCl73t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starmpcc/CS470-Team-23/blob/master/Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PInEwWsmRA_"
      },
      "source": [
        "CS470 Team 25 Project Classifier\n",
        "\n",
        "References\n",
        "\n",
        "\n",
        "*   https://tutorials.pytorch.kr/intermediate/torchvision_tutorial.html\n",
        "*   https://github.com/pytorch/vision/blob/21153802a3086558e9385788956b0f2808b50e51/torchvision/models/resnet.py#L161\n",
        "*   https://papers.nips.cc/paper/2017/file/e7e23670481ac78b3c4122a99ba60573-Paper.pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYDTpDVHhyCW",
        "outputId": "5705cb6d-d0b1-4b14-e79c-e1f86194073a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet34\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root = os.getcwd()+'/gdrive/My Drive/Colab Notebooks/Project'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgWusRusRjfw"
      },
      "source": [
        "#define hyperparameters\n",
        "val_set_ratio = 0.25\n",
        "learning_rate = 0.01\n",
        "num_epoches = 50\n",
        "num_classes = 91"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_Du0A3I6Ggx"
      },
      "source": [
        "def rec_freeze(model):\n",
        "  for child in model.children():\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False\n",
        "    rec_freeze(child)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcHlq5p9h7ai",
        "outputId": "3c600ac9-a369-4585-9eb8-92d9ad1e295c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Old Dataloader\n",
        "#Assume that all images are saved in \"cat\" folder\n",
        "\n",
        "#temporary loader for raw image\n",
        "\"\"\"\n",
        "temp_transform = transforms.Compose([\n",
        "                                      transforms.Resize(224),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),])\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(os.path.join(root, \"cat\"), temp_transform)\n",
        "#Use ConcatDataset to use refined data\n",
        "train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size = val_set_ratio)\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
        "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, 10, True, num_workers = 8)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, 10, True, num_workers = 8)\n",
        "\n",
        "print(len(dataset))\n",
        "print(len(train_dataset))\n",
        "print(len(val_dataset))\n",
        "\"\"\""
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5594\n",
            "4195\n",
            "1399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhOOINuGDnDG"
      },
      "source": [
        "#Read Pre-processed data\n",
        "face_data = torch.zeros(100, 100, 10).to(device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo9Uc-Eu6MD7",
        "outputId": "a5731f0e-7ab0-4104-c4ba-64f427d44f5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#temporary loader for raw image\n",
        "temp_transform = transforms.Compose([\n",
        "                                      transforms.Resize(224),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),])\n",
        "\n",
        "class CatFaceDataset(torch.utils.data.Dataset):\n",
        "  #Dict {image:Tensor(B*224*224), label:int, index:int}\n",
        "\n",
        "  def __init__(self, root, transform):\n",
        "    self.root = root\n",
        "    self.imgs = []\n",
        "    self.cats = list(sorted(os.listdir(os.path.join(root, \"cat\"))))\n",
        "    for cat in self.cats:\n",
        "      imagelist = list(sorted(os.listdir(os.path.join(root, \"cat\", cat))))\n",
        "      self.imgs += [os.path.join(root, \"cat\", cat, i) for i in imagelist]\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = Image.open(self.imgs[idx]).convert(\"RGB\")\n",
        "    img = self.transform(img)\n",
        "    label = self.imgs[idx].split('/')[-2].split('_')[-1]\n",
        "    index = int(os.path.basename(self.imgs[idx]).split('.')[0])\n",
        "    target = {}    \n",
        "    target[\"image\"] = img\n",
        "    target[\"label\"] = int(label)\n",
        "    target[\"index\"] = int(index)\n",
        "    return target\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n",
        "\n",
        "dataset = CatFaceDataset(root, temp_transform)\n",
        "#Use ConcatDataset to use refined data\n",
        "train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size = val_set_ratio)\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
        "val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, 10, True, num_workers = 8)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, 10, True, num_workers = 8)\n",
        "\n",
        "print(len(dataset))\n",
        "print(len(train_dataset))\n",
        "print(len(val_dataset))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5601\n",
            "4200\n",
            "1401\n",
            "(0, {'image': tensor([[[[0.2235, 0.2157, 0.2118,  ..., 0.2941, 0.2902, 0.2863],\n",
            "          [0.2235, 0.2157, 0.2118,  ..., 0.2941, 0.2902, 0.2863],\n",
            "          [0.2235, 0.2157, 0.2118,  ..., 0.2941, 0.2902, 0.2863],\n",
            "          ...,\n",
            "          [0.9020, 0.9098, 0.9216,  ..., 0.7529, 0.7569, 0.7451],\n",
            "          [0.8902, 0.9020, 0.8902,  ..., 0.7569, 0.7529, 0.7373],\n",
            "          [0.8667, 0.8784, 0.8745,  ..., 0.7608, 0.7490, 0.7529]],\n",
            "\n",
            "         [[0.1608, 0.1529, 0.1490,  ..., 0.2745, 0.2706, 0.2667],\n",
            "          [0.1608, 0.1529, 0.1490,  ..., 0.2745, 0.2706, 0.2667],\n",
            "          [0.1608, 0.1529, 0.1490,  ..., 0.2745, 0.2706, 0.2667],\n",
            "          ...,\n",
            "          [0.8745, 0.8824, 0.8941,  ..., 0.7686, 0.7725, 0.7608],\n",
            "          [0.8510, 0.8667, 0.8588,  ..., 0.7725, 0.7686, 0.7529],\n",
            "          [0.8196, 0.8392, 0.8392,  ..., 0.7765, 0.7647, 0.7686]],\n",
            "\n",
            "         [[0.1020, 0.0941, 0.0902,  ..., 0.2000, 0.1961, 0.1922],\n",
            "          [0.1020, 0.0941, 0.0902,  ..., 0.2000, 0.1961, 0.1922],\n",
            "          [0.1020, 0.0941, 0.0902,  ..., 0.2000, 0.1961, 0.1922],\n",
            "          ...,\n",
            "          [0.8392, 0.8471, 0.8588,  ..., 0.7725, 0.7765, 0.7647],\n",
            "          [0.8157, 0.8314, 0.8235,  ..., 0.7765, 0.7725, 0.7569],\n",
            "          [0.7882, 0.8039, 0.8000,  ..., 0.7804, 0.7686, 0.7725]]],\n",
            "\n",
            "\n",
            "        [[[0.0706, 0.0510, 0.2588,  ..., 0.1451, 0.1412, 0.1333],\n",
            "          [0.0431, 0.0627, 0.0667,  ..., 0.1373, 0.1412, 0.1373],\n",
            "          [0.1255, 0.0549, 0.0627,  ..., 0.1373, 0.1373, 0.1373],\n",
            "          ...,\n",
            "          [0.2196, 0.2000, 0.1804,  ..., 0.5255, 0.5176, 0.5176],\n",
            "          [0.2078, 0.2078, 0.2118,  ..., 0.5373, 0.5216, 0.5137],\n",
            "          [0.2000, 0.2078, 0.2235,  ..., 0.5294, 0.5098, 0.5059]],\n",
            "\n",
            "         [[0.0784, 0.0549, 0.2549,  ..., 0.1490, 0.1451, 0.1373],\n",
            "          [0.0431, 0.0627, 0.0667,  ..., 0.1412, 0.1451, 0.1412],\n",
            "          [0.1216, 0.0510, 0.0588,  ..., 0.1412, 0.1412, 0.1412],\n",
            "          ...,\n",
            "          [0.0863, 0.0784, 0.0824,  ..., 0.3843, 0.3765, 0.3765],\n",
            "          [0.0824, 0.0784, 0.0824,  ..., 0.3961, 0.3804, 0.3725],\n",
            "          [0.0863, 0.0784, 0.0784,  ..., 0.3882, 0.3686, 0.3647]],\n",
            "\n",
            "         [[0.0667, 0.0510, 0.2510,  ..., 0.1176, 0.1137, 0.1059],\n",
            "          [0.0431, 0.0627, 0.0627,  ..., 0.1098, 0.1137, 0.1098],\n",
            "          [0.1216, 0.0549, 0.0588,  ..., 0.1098, 0.1098, 0.1098],\n",
            "          ...,\n",
            "          [0.0157, 0.0157, 0.0235,  ..., 0.2431, 0.2353, 0.2353],\n",
            "          [0.0039, 0.0078, 0.0235,  ..., 0.2549, 0.2392, 0.2314],\n",
            "          [0.0000, 0.0039, 0.0157,  ..., 0.2471, 0.2275, 0.2235]]],\n",
            "\n",
            "\n",
            "        [[[0.8000, 0.8000, 0.7922,  ..., 0.1137, 0.1176, 0.0745],\n",
            "          [0.7922, 0.7804, 0.7176,  ..., 0.0902, 0.0941, 0.0706],\n",
            "          [0.7686, 0.7255, 0.5725,  ..., 0.0510, 0.0510, 0.0549],\n",
            "          ...,\n",
            "          [0.8235, 0.8235, 0.8196,  ..., 0.6784, 0.6824, 0.6824],\n",
            "          [0.8235, 0.8235, 0.8196,  ..., 0.6824, 0.6824, 0.6824],\n",
            "          [0.8275, 0.8235, 0.8196,  ..., 0.7059, 0.6863, 0.6863]],\n",
            "\n",
            "         [[0.8196, 0.8196, 0.8118,  ..., 0.0902, 0.0941, 0.0510],\n",
            "          [0.8118, 0.8000, 0.7373,  ..., 0.0667, 0.0706, 0.0471],\n",
            "          [0.7882, 0.7451, 0.5922,  ..., 0.0275, 0.0275, 0.0314],\n",
            "          ...,\n",
            "          [0.8353, 0.8353, 0.8314,  ..., 0.7059, 0.7098, 0.7098],\n",
            "          [0.8353, 0.8353, 0.8314,  ..., 0.7098, 0.7098, 0.7098],\n",
            "          [0.8392, 0.8353, 0.8314,  ..., 0.7333, 0.7137, 0.7137]],\n",
            "\n",
            "         [[0.8353, 0.8353, 0.8275,  ..., 0.0902, 0.0941, 0.0510],\n",
            "          [0.8275, 0.8157, 0.7529,  ..., 0.0667, 0.0706, 0.0471],\n",
            "          [0.8039, 0.7608, 0.6078,  ..., 0.0275, 0.0275, 0.0314],\n",
            "          ...,\n",
            "          [0.8549, 0.8549, 0.8510,  ..., 0.7294, 0.7333, 0.7333],\n",
            "          [0.8549, 0.8549, 0.8510,  ..., 0.7333, 0.7333, 0.7333],\n",
            "          [0.8588, 0.8549, 0.8510,  ..., 0.7569, 0.7373, 0.7373]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.4196, 0.4627, 0.5765,  ..., 0.4000, 0.4078, 0.4078],\n",
            "          [0.3922, 0.4118, 0.4549,  ..., 0.3922, 0.4078, 0.4118],\n",
            "          [0.3922, 0.4000, 0.4196,  ..., 0.3804, 0.4039, 0.4157],\n",
            "          ...,\n",
            "          [0.6902, 0.6431, 0.6314,  ..., 0.8510, 0.8471, 0.8510],\n",
            "          [0.6431, 0.6196, 0.6039,  ..., 0.8039, 0.8196, 0.8353],\n",
            "          [0.6000, 0.5843, 0.5686,  ..., 0.7843, 0.7882, 0.8039]],\n",
            "\n",
            "         [[0.2863, 0.3294, 0.4510,  ..., 0.2627, 0.2745, 0.2784],\n",
            "          [0.2588, 0.2784, 0.3216,  ..., 0.2588, 0.2745, 0.2784],\n",
            "          [0.2549, 0.2588, 0.2784,  ..., 0.2510, 0.2706, 0.2784],\n",
            "          ...,\n",
            "          [0.4784, 0.4353, 0.4275,  ..., 0.5961, 0.5882, 0.5843],\n",
            "          [0.4431, 0.4196, 0.4039,  ..., 0.5451, 0.5608, 0.5686],\n",
            "          [0.4039, 0.3882, 0.3804,  ..., 0.5255, 0.5294, 0.5373]],\n",
            "\n",
            "         [[0.1804, 0.2157, 0.3255,  ..., 0.1647, 0.1647, 0.1608],\n",
            "          [0.1569, 0.1686, 0.2078,  ..., 0.1412, 0.1608, 0.1686],\n",
            "          [0.1569, 0.1569, 0.1686,  ..., 0.1137, 0.1529, 0.1725],\n",
            "          ...,\n",
            "          [0.2431, 0.2039, 0.2039,  ..., 0.3529, 0.3412, 0.3373],\n",
            "          [0.2235, 0.2039, 0.2000,  ..., 0.3020, 0.3137, 0.3216],\n",
            "          [0.1961, 0.1843, 0.1843,  ..., 0.2824, 0.2784, 0.2902]]],\n",
            "\n",
            "\n",
            "        [[[0.5294, 0.5294, 0.5294,  ..., 0.6431, 0.6431, 0.6353],\n",
            "          [0.5294, 0.5294, 0.5294,  ..., 0.6353, 0.6353, 0.6392],\n",
            "          [0.5294, 0.5294, 0.5294,  ..., 0.6353, 0.6392, 0.6392],\n",
            "          ...,\n",
            "          [0.6549, 0.6784, 0.6627,  ..., 0.7843, 0.7882, 0.8392],\n",
            "          [0.6706, 0.6627, 0.6510,  ..., 0.7843, 0.7882, 0.8275],\n",
            "          [0.6627, 0.6431, 0.6627,  ..., 0.7804, 0.7882, 0.8353]],\n",
            "\n",
            "         [[0.5020, 0.5020, 0.5020,  ..., 0.5804, 0.5804, 0.5765],\n",
            "          [0.5020, 0.5020, 0.5020,  ..., 0.5725, 0.5725, 0.5804],\n",
            "          [0.5020, 0.5020, 0.5020,  ..., 0.5725, 0.5765, 0.5804],\n",
            "          ...,\n",
            "          [0.5882, 0.6118, 0.5961,  ..., 0.7137, 0.7020, 0.7412],\n",
            "          [0.6039, 0.5961, 0.5843,  ..., 0.7137, 0.7020, 0.7255],\n",
            "          [0.5961, 0.5765, 0.5961,  ..., 0.7098, 0.7020, 0.7373]],\n",
            "\n",
            "         [[0.4627, 0.4627, 0.4627,  ..., 0.5216, 0.5137, 0.5059],\n",
            "          [0.4627, 0.4627, 0.4627,  ..., 0.5098, 0.5098, 0.5059],\n",
            "          [0.4627, 0.4627, 0.4627,  ..., 0.5137, 0.5098, 0.5059],\n",
            "          ...,\n",
            "          [0.5176, 0.5412, 0.5255,  ..., 0.6235, 0.6078, 0.6431],\n",
            "          [0.5333, 0.5255, 0.5137,  ..., 0.6235, 0.6118, 0.6275],\n",
            "          [0.5255, 0.5059, 0.5255,  ..., 0.6196, 0.6078, 0.6392]]],\n",
            "\n",
            "\n",
            "        [[[0.8588, 0.8627, 0.8667,  ..., 0.8471, 0.8471, 0.8431],\n",
            "          [0.8627, 0.8627, 0.8627,  ..., 0.8471, 0.8471, 0.8431],\n",
            "          [0.8667, 0.8627, 0.8588,  ..., 0.8471, 0.8471, 0.8431],\n",
            "          ...,\n",
            "          [0.8627, 0.8627, 0.8627,  ..., 0.3490, 0.3098, 0.3216],\n",
            "          [0.8627, 0.8627, 0.8627,  ..., 0.3451, 0.3529, 0.3333],\n",
            "          [0.8627, 0.8627, 0.8627,  ..., 0.3176, 0.3373, 0.3137]],\n",
            "\n",
            "         [[0.8431, 0.8471, 0.8510,  ..., 0.8196, 0.8196, 0.8157],\n",
            "          [0.8471, 0.8471, 0.8471,  ..., 0.8196, 0.8196, 0.8157],\n",
            "          [0.8510, 0.8471, 0.8431,  ..., 0.8196, 0.8196, 0.8157],\n",
            "          ...,\n",
            "          [0.8471, 0.8471, 0.8471,  ..., 0.3098, 0.2706, 0.2824],\n",
            "          [0.8471, 0.8471, 0.8471,  ..., 0.3059, 0.3137, 0.2941],\n",
            "          [0.8471, 0.8471, 0.8471,  ..., 0.2784, 0.2980, 0.2745]],\n",
            "\n",
            "         [[0.8078, 0.8118, 0.8157,  ..., 0.7804, 0.7804, 0.7765],\n",
            "          [0.8118, 0.8118, 0.8118,  ..., 0.7804, 0.7804, 0.7765],\n",
            "          [0.8157, 0.8118, 0.8078,  ..., 0.7804, 0.7804, 0.7765],\n",
            "          ...,\n",
            "          [0.8118, 0.8118, 0.8118,  ..., 0.2745, 0.2353, 0.2471],\n",
            "          [0.8118, 0.8118, 0.8118,  ..., 0.2706, 0.2784, 0.2588],\n",
            "          [0.8118, 0.8118, 0.8118,  ..., 0.2431, 0.2627, 0.2392]]]]), 'label': tensor([43, 45, 29,  3, 63, 31, 88, 78, 17,  8]), 'index': tensor([16, 77, 42, 32, 44, 25, 56, 40,  6, 19])})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am9w9pEzsVfU"
      },
      "source": [
        "class ACNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ACNN, self).__init__()\n",
        "\n",
        "    #Get layers from pretrained resnet34\n",
        "    resnet = resnet34(pretrained = True)\n",
        "    l = []\n",
        "    for child in resnet.children():\n",
        "      l.append(child)\n",
        "    \n",
        "    #Original layers from resnet34\n",
        "    self.conv1 = l[0]\n",
        "    self.bn1 = l[1]\n",
        "    self.relu = l[2]\n",
        "    self.maxpool = l[3]\n",
        "    self.layer1 = l[4]\n",
        "    self.layer2 = l[5]\n",
        "    self.layer3 = l[6]\n",
        "    self.layer4 = l[7]\n",
        "    self.avgpool = l[8]\n",
        "#    self.fc = l[9]\n",
        "\n",
        "    #Re-Define final fc layer to adapt our model\n",
        "    self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    #define new layers for Adaptive Convolution\n",
        "    self.param_ln1 = nn.Linear(1, 1)\n",
        "\n",
        "  #TODO: freeze some layers\n",
        "  def forward(self, x, cat_face_data):\n",
        "        #B*3*224*224\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        #B*64*32*32\n",
        "        x = self.layer1(x)\n",
        "        #B*64*32*32\n",
        "        x = self.layer2(x)\n",
        "        #B*128*16*16\n",
        "        x = self.layer3(x)\n",
        "        #B*256*8*8\n",
        "        x = self.layer4(x)\n",
        "        #B*512*4*4\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        #B*512\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnjLOlkRh7gG"
      },
      "source": [
        "# Define Model\n",
        "model = ACNN().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPp0NU6Hh7jW"
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), learning_rate)\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "\n",
        "fitness = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(num_epoches):\n",
        "  model.train()\n",
        "  cnt = 0\n",
        "  correct_cnt = 0\n",
        "  train_loss = 0.0\n",
        "  for idx, target in enumerate(train_dataloader):\n",
        "    print(target[\"label\"])\n",
        "    x = target[\"image\"].to(device)\n",
        "    label = target[\"label\"].to(device)\n",
        "    cat_face_data = face_data[label, target[\"index\"], :]\n",
        "\n",
        "    pred = model(x, cat_face_data)\n",
        "    optimizer.zero_grad()\n",
        "    train_loss = fitness(pred, label)\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    _, correct = torch.max(pred, 1)\n",
        "    correct_cnt += (correct == label.data).sum().item()\n",
        "    cnt += x.data.size(0)\n",
        "\n",
        "  train_losses.append(train_loss)\n",
        "  train_accs.append(correct_cnt/cnt)\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "  cnt = 0\n",
        "  correct_cnt = 0\n",
        "  val_loss = 0.0\n",
        "  for idx, target in enumerate(val_dataloader):\n",
        "    with torch.no_grad():\n",
        "      x = target[\"image\"].to(device)\n",
        "      label = target[\"label\"].to(device)\n",
        "      cat_face_data = face_data[label, target[\"index\"], :]\n",
        "\n",
        "      pred = model(x, cat_face_data)\n",
        "      pred = model(x)\n",
        "      val_loss = fitness(pred, label)\n",
        "      _, correct = torch.max(pred, 1)\n",
        "      correct_cnt += (correct == label.data).sum().item()\n",
        "      cnt += x.data.size(0)\n",
        "\n",
        "  val_losses.append(val_loss)\n",
        "  val_accs.append(correct_cnt/cnt)\n",
        "\n",
        "  print(f\"{epoch}th epoch,  train_loss: {train_loss}, val_loss: {val_loss}\")\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}